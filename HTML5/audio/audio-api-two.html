<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="./audio-aip-two.css">
    <title>audio Web API 音频可视化</title>
</head>
<body>
    <div class="content">
        <h1>audio Web API 音频可视化</h1>
        <button>播放歌曲一</button>
        <button>播放歌曲二</button>
        <input type="file" id="update" value="选择本地音乐">
      
    </div>
    <div class="voice">
        <button class="voiceAdd">音量 + </button>
        <button class="voiceReduce">音量 - </button>
    </div>
    <div class="canvasWrap">
        <canvas id="canvas" width="770" height="500"></canvas>
    </div>
    <script>

             let input = document.getElementById("update")
             let canvas = document.getElementById("canvas")
             let animateTiemId, // 定时器id
             volume = 0.2   // 存储声音音量
                             
              //创建音频接口上下文
             let audioCtx = new (AudioContext || webkitAudioContext)();

             // 创建实时频率及时间信息对象
             let analyser = audioCtx.createAnalyser()


             // 上传音乐时触发
             input.onchange = function(e){ 
                 disposeFile(e.target.files[0])
             }



            // 处理本地上传音频文件，转化为arrayBuffer 二进制 
            function disposeFile(file){ 
                let fs = new FileReader();
                fs.readAsArrayBuffer(file)
                fs.onload = function (e){
                    // 解码音轨
                    audioCtx.decodeAudioData(e.target.result,function(buf){
                        
                        //创建一个 `AudioBufferSourceNode` 对象，该对象可以处理包含在内的音频数据
                        let musicSource = audioCtx.createBufferSource()
                        musicSource.buffer = buf;

                        createMusic(musicSource)
                    },function(e){
                        alert("文件解析出错")
                    })
                }
               
            }

            // 处理 audio 元素获得音频

            function audioMusic(){
                let audio = document.createElement('audio')
                audio.src = ""

            }
            
            // 生成音乐 （处理音频 声音等）
            function createMusic(musicSource){

                /***创建音量控制节点**/
                var gainNode = audioCtx.createGain();    
                gainNode.gain.setValueAtTime(0, audioCtx.currentTime);// 先把当前音量设为0 
                // 3秒时间内音量从刚刚的0变成0.2，线性变化  
                gainNode.gain.linearRampToValueAtTime(volume, audioCtx.currentTime + 3);
             
                /***  将音量链接到音频  ***/
                musicSource.connect(gainNode);
                
                /** 将频率及时间信息对象 与音频 链接**/ 
                musicSource.connect(analyser);

                  /** 将频率及时间信息对象 与 声音对象链接**/ 
                analyser.connect(gainNode);

                /*** 将音量与设备关联 ***/
                gainNode.connect(audioCtx.destination);

                /*** 开始播放声音 ***/
                musicSource.start(audioCtx.currentTime);
                // musicSource.stop(audioCtx.currentTime + 10);
                musicSource.onended = function(){
                    console.log("结束了")
                     /***  断开音量与音频的链接  ***/
                    musicSource.disconnect(gainNode);
                  
                    musicSource.disconnect(analyser);
                    analyser.disconnect(gainNode);

                    /*** 将音量与设备关联 ***/
                    gainNode.disconnect(audioCtx.destination);

                    // 音乐播放完成后清楚定时器
                    if(!animateTiemId)
                       cancelAnimationFrame(animateTiemId)
                    
                }

                       // 音量控制

                    document.querySelector('.voiceAdd').addEventListener('click',add)

                    function add(){
                        // 增加音量
                        volume = volume >= 1.2?1.2:(Number(volume) + 0.1).toFixed(1)
                        gainNode.gain.linearRampToValueAtTime(volume, audioCtx.currentTime);
                        console.log(volume)
                    }

                      document.querySelector('.voiceReduce').addEventListener('click',function(){
                        // 减小音量
                        volume = volume <= 0?0:(Number(volume) - 0.1).toFixed(1)
                        gainNode.gain.linearRampToValueAtTime(volume, audioCtx.currentTime);
                        console.log(volume)
                    })

            }
           
            
// 创建画布

        function Cvs(canvas){
           this.ctx = canvas.getContext('2d') 
           this.sum = 32 // 可视化的音频个数 不要超过64
           this.analyserAry = [] // 存储的每个音频条形图的高度
           this.aryX = [] // 存储的每个音频条形图的X轴位置
           this.w = 20 // 每个条形图的宽度
           this.h = 5; // 每个小长条的高度
           this.width = canvas.width; // canvas 真实宽度
           this.height = canvas.height; // canvas真实高度
           // 条形图渐变
           this.grd = this.ctx.createLinearGradient(0, 150, 0, 500);
           this.grd.addColorStop(0, "red");
           this.grd.addColorStop(0.5, "yellow");
           this.grd.addColorStop(1, "#00E800");

           this.init()
        }

        Cvs.prototype.init = function(){ 
            // 初始化时确定每个条形音频的X轴位置
            let positionX = 10;
            for(let i=0;i<this.sum;i++){
                positionX = positionX + this.w + 2 // 这个5是每个条形图的间隔
                this.aryX.push(positionX)
            }
            this.draw()
        }
        
        // 更新可视化图像
        Cvs.prototype.update = function(bufAry){
           this.disposeAnalyser(bufAry)
        }

        // 处理音频数据转化为可视化数据
        Cvs.prototype.disposeAnalyser = function(bufAry){ 
           let len = bufAry.length; // 音频数组长度
           let ary = []; 
           // 保留32个音频数据，一共1024个
           for(let i=0;i<len;i+=32){ 
               ary.push(bufAry[i])
           }
           this.analyserAry = ary
        }

        // 绘制canvas
        Cvs.prototype.draw = function(){
            this.ctx.clearRect(0,0,this.width,this.height);
            this.ctx.fillStyle = "#111";
            this.ctx.fillRect(0, 0, this.width, this.height);
            for(let i = 0;i<this.sum;i++){ // 循环每个条形音频
                let height = this.analyserAry[i]*2 // 每个条形音频的高度(加大十倍)
                //计算条形音频大概有多少个小长条(取整数) 小长条高度+间隔
                let rectaSum = Math.floor(height/(this.h + 2)) + 1 // 至少一个
                let positionY = this.height;
                // 循环要绘制的小长方格
                for(let s=0;s<rectaSum;s++){
                    positionY = positionY - this.h - 2
                    this.rectangle(this.aryX[i],positionY) 
                }
            }
           
        }

        // 绘制小长方格
        Cvs.prototype.rectangle = function(x,y){
            this.ctx.fillStyle= this.grd;
            this.ctx.fillRect(x,y,this.w,this.h);
        }


        
        let newCvs = new Cvs(canvas);

        // 开启定时器
        function animationFra(){
            let array_length = analyser.frequencyBinCount;
            let arrayBuf = new Uint8Array(array_length);
            analyser.getByteFrequencyData(arrayBuf);	//将音频节点的数据拷贝到Uin8Array中
            
            newCvs.update(arrayBuf) // 处理arryBuff
            newCvs.draw() // 绘制 canvas
            animateTiemId = requestAnimationFrame(animationFra) 
        }
        animationFra()
        



      
    </script>   
</body>
</html>