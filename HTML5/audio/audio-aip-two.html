<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="./audio-aip-two.css">
    <title>audio Web API 音频可视化</title>
</head>
<body>
   
    <div class="content">
        <h1>audio Web API 音频可视化</h1>
        <input type="file" id="update">
        <button>播放</button>
        <button>静音</button>
    </div>
    <div class="canvasWrap">
        <canvas id="canvas"></canvas>
    </div>
    <script>

             let input = document.getElementById("update")
             let canvas = document.getElementById("canvas")

              //创建音频接口上下文
             let audioCtx = new (AudioContext || webkitAudioContext)();


             // 上传音乐时触发
             input.onchange = function(e){ 
                 disposeFile(e.target.files[0])
             }



            // 处理音频文件，转化为arrayBuffer 二进制
            function disposeFile(file){ 
                let fs = new FileReader();
                fs.readAsArrayBuffer(file)
                fs.onload = function (e){
                    // 解码音轨
                    audioCtx.decodeAudioData(e.target.result,function(buf){
                        createMusic(buf)
                    },function(e){
                        alert("文件解析出错")
                    })
                }
               
            }
            
            let analyser = audioCtx.createAnalyser()

            // 生成音乐
            function createMusic(buf){
                
                //创建一个 `AudioBufferSourceNode` 对象，该对象可以处理包含在内的音频数据
                let musicSource = audioCtx.createBufferSource()
                musicSource.buffer = buf;

                /***创建音量控制节点**/
                var gainNode = audioCtx.createGain();    
                gainNode.gain.setValueAtTime(0, audioCtx.currentTime);// 先把当前音量设为0 
                // 3秒时间内音量从刚刚的0变成0.5，线性变化  
                gainNode.gain.linearRampToValueAtTime(0.2, audioCtx.currentTime + 3);
             
                /***  将音量链接到音频  ***/
                musicSource.connect(gainNode);
              
                musicSource.connect(analyser);
                analyser.connect(gainNode);

                /*** 将音量与设备关联 ***/
                gainNode.connect(audioCtx.destination);


                /*** 开始播放声音 ***/
                musicSource.start(audioCtx.currentTime);
                // musicSource.stop(audioCtx.currentTime + 10);
                musicSource.onended = function(){
                    console.log("结束了")
                     /***  将音量链接到音频  ***/
                    musicSource.disconnect(gainNode);
                
                    musicSource.disconnect(analyser);
                    analyser.disconnect(gainNode);

                    /*** 将音量与设备关联 ***/
                    gainNode.disconnect(audioCtx.destination);
                }
            }
           
            
// 创建画布

        function Cvs(canvas){
           this.ctx = canvas.getContext('2d') 
           this.sum = 32 // 可视化的音频个数 不要超过64
           this.analyserAry = [] // 存储的每个音频条形图的高度
           this.aryX = [] // 存储的每个音频条形图的X轴位置
           this.w = 15; // 每个条形图的宽度
           this.h = 10; // 每个小长条的高度
           this.width = canvas.offsetWidth; // canvas 真实宽度
           this.height = canvas.offsetHeight; // canvas真实高度
           this.init()
        }

        Cvs.prototype.init = function(){
            // 初始化时确定每个条形音频的X轴位置
            let positionX = 20;
            for(let i=0;i<this.sum;i++){
                positionX = positionX + this.w + 5 // 这个5是每个条形图的间隔
                this.aryX.push(positionX)
            }
            this.draw()
        }
        
        // 更新可视化图像
        Cvs.prototype.update = function(bufAry){
           this.disposeAnalyser(bufAry)
        }

        // 处理音频数据转化为可视化数据
        Cvs.prototype.disposeAnalyser = function(bufAry){ 
           let len = bufAry.length; // 音频数组长度
           let ary = []; 
           for(let i=0;i<len;i+=16){
               if(ary.length<this.sum){
                 ary.push(bufAry[i])
               }else{
                   break;
               }
           }
           this.analyserAry = ary
        }

        // 绘制canvas
        Cvs.prototype.draw = function(){

            for(let i = 0;i<this.sum;i++){ // 循环每个条形音频
                let height = this.analyserAry[i]*5 // 每个条形音频的高度(加大十倍)
                //计算条形音频大概有多少个小长条(取整数) 小长条高度+间隔
                let rectaSum = Math.floor(height/(this.h + 5)) 
                let everyH = 0;

                for(let s=0;s<rectaSum;s++){

                    this.rectangle(this.aryX[i],everyH) 
                    everyH = everyH + this.h + 5
                }
            }
            this.ctx.fillstyle = "#111"
            this.ctx.fillRect(0,0,this.width,this.height);
        }

        // 绘制小长方格
        Cvs.prototype.rectangle = function(x,y){
            this.ctx.beginPath();
            this.ctx.arc(x,y,this.radius,0,2*Math.PI);
            this.ctx.fillStyle = this.color
            this.ctx.fill();
            this.ctx.closePath();
            console.log(x,y)
        }



       
        
   let newCvs = new Cvs(canvas);


    setInterval(() => {
        let array_length = analyser.frequencyBinCount;
        let arrayBuf = new Uint8Array(array_length);
        analyser.getByteFrequencyData(arrayBuf);	//将音频节点的数据拷贝到Uin8Array中
        
        newCvs.update(arrayBuf) // 处理arryBuff
        newCvs.draw()
    }, 2000);

    </script>   
</body>
</html>