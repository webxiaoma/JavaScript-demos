<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="./audio-aip-two.css">
    <title>audio Web API 音频可视化</title>
</head>
<body>
   
    <div class="content">
        <h1>audio Web API 音频可视化</h1>
        <input type="file" id="update">
        <button>播放</button>
        <button>静音</button>
    </div>
    <div class="canvasWrap">
        <canvas id="canvas" width="800" height="500"></canvas>
    </div>
    <script>

             let input = document.getElementById("update")
             let canvas = document.getElementById("canvas")

              //创建音频接口上下文
             let audioCtx = new (AudioContext || webkitAudioContext)();
             let analyser = audioCtx.createAnalyser()


             // 上传音乐时触发
             input.onchange = function(e){ 
                 disposeFile(e.target.files[0])
             }



            // 处理音频文件，转化为arrayBuffer 二进制
            function disposeFile(file){ 
                let fs = new FileReader();
                fs.readAsArrayBuffer(file)
                fs.onload = function (e){
                    // 解码音轨
                    audioCtx.decodeAudioData(e.target.result,function(buf){
                        createMusic(buf)
                    },function(e){
                        alert("文件解析出错")
                    })
                }
               
            }
            

            // 生成音乐
            function createMusic(buf){
                
                //创建一个 `AudioBufferSourceNode` 对象，该对象可以处理包含在内的音频数据
                let musicSource = audioCtx.createBufferSource()
                musicSource.buffer = buf;

                /***创建音量控制节点**/
                var gainNode = audioCtx.createGain();    
                gainNode.gain.setValueAtTime(0, audioCtx.currentTime);// 先把当前音量设为0 
                // 3秒时间内音量从刚刚的0变成0.5，线性变化  
                gainNode.gain.linearRampToValueAtTime(0.2, audioCtx.currentTime + 3);
             
                /***  将音量链接到音频  ***/
                musicSource.connect(gainNode);
              
                musicSource.connect(analyser);
                analyser.connect(gainNode);

                /*** 将音量与设备关联 ***/
                gainNode.connect(audioCtx.destination);


                /*** 开始播放声音 ***/
                musicSource.start(audioCtx.currentTime);
                // musicSource.stop(audioCtx.currentTime + 10);
                musicSource.onended = function(){
                    console.log("结束了")
                     /***  将音量链接到音频  ***/
                    musicSource.disconnect(gainNode);
                
                    musicSource.disconnect(analyser);
                    analyser.disconnect(gainNode);

                    /*** 将音量与设备关联 ***/
                    gainNode.disconnect(audioCtx.destination);
                }
            }
           
            
// 创建画布

        function Cvs(canvas){
           this.ctx = canvas.getContext('2d') 
           this.sum = 32 // 可视化的音频个数 不要超过64
           this.analyserAry = [] // 存储的每个音频条形图的高度
           this.aryX = [] // 存储的每个音频条形图的X轴位置
           this.w = 20 // 每个条形图的宽度
           this.h = 5; // 每个小长条的高度
           this.width = canvas.width; // canvas 真实宽度
           this.height = canvas.height; // canvas真实高度
           // 条形图渐变
           this.grd = this.ctx.createLinearGradient(0, 150, 0, 500);
           this.grd.addColorStop(0, "red");
           this.grd.addColorStop(0.5, "yellow");
           this.grd.addColorStop(1, "#00E800");

           this.init()
        }

        Cvs.prototype.init = function(){
            // 初始化时确定每个条形音频的X轴位置
            let positionX = 10;
            for(let i=0;i<this.sum;i++){
                positionX = positionX + this.w + 2 // 这个5是每个条形图的间隔
                this.aryX.push(positionX)
            }
            this.draw()
        }
        
        // 更新可视化图像
        Cvs.prototype.update = function(bufAry){
           this.disposeAnalyser(bufAry)
        }

        // 处理音频数据转化为可视化数据
        Cvs.prototype.disposeAnalyser = function(bufAry){ 
           let len = bufAry.length; // 音频数组长度
           let ary = []; 
           for(let i=0;i<len;i+=32){
               ary.push(bufAry[i])
           }
           this.analyserAry = ary
        }

        // 绘制canvas
        Cvs.prototype.draw = function(){
            this.ctx.clearRect(0,0,this.width,this.height);
            this.ctx.fillStyle = "#111";
            this.ctx.fillRect(0, 0, this.width, this.height);
            for(let i = 0;i<this.sum;i++){ // 循环每个条形音频
                let height = this.analyserAry[i]*2 // 每个条形音频的高度(加大十倍)
                //计算条形音频大概有多少个小长条(取整数) 小长条高度+间隔
                let rectaSum = Math.floor(height/(this.h + 2)) + 1 // 至少一个
                let positionY = this.height;
                for(let s=0;s<rectaSum;s++){
                    positionY = positionY - this.h - 2
                    this.rectangle(this.aryX[i],positionY) 
                }
            }
           
        }

        // 绘制小长方格
        Cvs.prototype.rectangle = function(x,y){
            this.ctx.fillStyle= this.grd;
            this.ctx.fillRect(x,y,this.w,this.h);
        }



       
        
   let newCvs = new Cvs(canvas);

  
   function animationFra(){
    let array_length = analyser.frequencyBinCount;
    let arrayBuf = new Uint8Array(array_length);
    analyser.getByteFrequencyData(arrayBuf);	//将音频节点的数据拷贝到Uin8Array中
    
    newCvs.update(arrayBuf) // 处理arryBuff
    newCvs.draw()
    requestAnimationFrame(animationFra) 
   }
   animationFra()
  

    </script>   
</body>
</html>